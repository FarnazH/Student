{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Exercise in linear algebra and matrix mechanics.\"\"\"\n",
    "\n",
    "__authors__ = \"D. A. Sirianni\"\n",
    "__credits__ = [\"Daniel G. A. Smith\"]\n",
    "__email__   = [\"sirianni.dom@gmail.com\"]\n",
    "\n",
    "__copyright__ = \"(c) 2008-2019, The Psi4Education Developers\"\n",
    "__license__   = \"BSD-3-Clause\"\n",
    "__date__      = \"2019-11-18\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Notes\n",
    "\n",
    "#### Activity Summary\n",
    "This activity is intended to review the basics of matrix operations and to introduce generalized tensor\n",
    "contractions, Einstein summation convention, and the use of NumPy library functions to perform contractions\n",
    "efficiently.\n",
    "\n",
    "#### Prerequisite Knowledge\n",
    "This activity assumes that the students are familiar with basic matrix operations and linear algebra, but not\n",
    "at the level of a full semester-long course.  This activity also assumes all the [standard python pre-requisites\n",
    "of all Psi4Education labs](https://admiring-tesla-08529a.netlify.com/posts/psi4jupyter_labs/).  \n",
    "\n",
    "#### Learning ojbectives\n",
    "By the end of this lesson, students will be able to:\n",
    "1. Define common matrix operations (inner, outer, direct products) in summation notation,\n",
    "2. Implement matrix multiplication by hand in Python,\n",
    "3. Expand/contract tensor expressions using Einstein summation convention,\n",
    "4. Leverage library functions to implement tensor contractions from written formulas, and\n",
    "5. Justify strengths and weaknesses of the various tensor contraction engines.\n",
    "\n",
    "#### Expected Schedule\n",
    "This exercise is expected to require a full 3-hour laboratory period.\n",
    "\n",
    "Authors: Dominic A. Sirianni (sirianni.dom@gmail.com; [ORCID: 0000-0002-6464-0213](https://orcid.org/0000-0002-6464-0213) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Differential equations, which seek to find an unknown function through its relationship to its own derivative(s),\n",
    "are a universal language in the physical sciences and engineering which describe everything from electron\n",
    "dynamics to problems in civil engineering and aeronautics.  For advancements in these applications, solving\n",
    "differential equations accurately and efficiently is of crucial importance.  Unfortunately, many of these\n",
    "expressions do not have an analytical solution, meaning that only approximate solutions are available.  \n",
    "\n",
    "One of the most significant advantages of scientific computing is the efficiency with which computers\n",
    "can perform linear algebra operations and solve linear algebra expressions.  Therefore, in order to study the\n",
    "multitude of physical phenomena described by differential equations, an understanding of scientific computing and\n",
    "numerical linear algebra is of critical importance.\n",
    "\n",
    "\n",
    "## Representing Vectors & Matrices in Python\n",
    "\n",
    "A vector is simply an ordered collection of scalar components, and a matrix is simply an ordered collection of\n",
    "row (or column) vectors.  Therefore, we can represent these objects with any Python type that is a similarly\n",
    "ordered collection, including a `list` or `tuple`.  Often, we would like to be able to modify the elements of\n",
    "these objects, so generally using a `list` is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==> Arrays as Lists <==\n",
    "# Define a length-5 vector v\n",
    "v = [1, 2, 3, 4, 5]\n",
    "# Define two 3x3 matrices, A & B, as lists of row vectors\n",
    "A = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "B = [[10, 11, 12], [13, 14, 15], [16, 17, 18]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Operations: Scalars, Vectors, & Marices\n",
    "For matrices **A** and **B** and constants $r$ and $s$, \n",
    "#### Matrix Addition\n",
    "$${\\bf A} + {\\bf B} = \\begin{pmatrix}\n",
    "a & b\\\\\n",
    "c & d\n",
    "\\end{pmatrix} + \\begin{pmatrix}\n",
    "e & f\\\\\n",
    "g & h\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "a + e & b + f\\\\\n",
    "c + g & d + h\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Scalar Multiplication & Addition\n",
    "$$r\\cdot{\\bf A} + s= r\\cdot\\begin{pmatrix}\n",
    "a & b\\\\\n",
    "c & d\n",
    "\\end{pmatrix} + s = \\begin{pmatrix}\n",
    "r\\cdot a + s & r\\cdot b + s \\\\\n",
    "r\\cdot c + s & r\\cdot d + s \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Matrix Multiplication\n",
    "\n",
    "![Matrix multiplication](media/matmul.png)\n",
    "$${\\bf C} = \\sum_{i=1}^{M}\\sum_{k=1}^{N}\\sum_{j=1}^{P}A_{ik}B_{kj}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 84.  90.  96.]\n",
      " [201. 216. 231.]\n",
      " [318. 342. 366.]]\n"
     ]
    }
   ],
   "source": [
    "# ==> Implement the matrix product of A x B using Python for-loops <==\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "C = np.zeros((3,3))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            C[i, j] += A[i][k] * B[k][j]\n",
    "            \n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Built-In NumPy Functions\n",
    "\n",
    "1. `numpy.einsum()`\n",
    "2. `numpy.dot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==> Create two (3,3) matrices <==\n",
    "np_A = np.array(A)\n",
    "np_B = np.array(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==> Define a function which is reusable <==\n",
    "def matmul(a,b):\n",
    "    # Get the shapes of A & B\n",
    "    ai, ak = a.shape # n_rows * n_cols\n",
    "    bk, bj = b.shape\n",
    "    assert ak==bk # Check that the matrices are compatible\n",
    "    # Create (ai, bj) matrix to store the result\n",
    "    C = np.zeros((ai, bj))\n",
    "    for i in range(ai):\n",
    "        for k in range(bk):\n",
    "            for j in range(bj): # or br\n",
    "                C[i,j] += a[i,k] * b[k,j]\n",
    "                \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 5: 28.2 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit matmul(np_A, np_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 45.73 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 5: 845 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit np_A.dot(np_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Contractions: Generalized Matrix Multiplication\n",
    "\n",
    "The way we've defined the matrix product, we may only multiply compatible arrays, which share the same \"inner\"\n",
    "dimensions, which yields a matrix with the \"outer\" dimensions.  By using the definition of matrix multiplication\n",
    "written as a triple summation, however, we can generalize this operation to yield other shapes as well.\n",
    "\n",
    "Given two (3, 5) rectangular matrices $A$ and $B$, let's consider the following expressions:\n",
    "\n",
    "1. \"Inner\" Product\n",
    "$${\\bf M} = A\\times B^{\\rm T}$$\n",
    "\n",
    "2. \"Outer\" Product\n",
    "$${\\bf N} = A^{\\rm T}\\times B$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the inner product is (3, 3)\n",
      "[[0.92698283 1.3011426  0.69503391]\n",
      " [1.67945146 2.21216242 1.6315874 ]\n",
      " [1.75203946 1.99938055 1.15459474]]\n",
      "The shape of the outer product is (5, 5)\n",
      "[[0.87283543 1.0290475  0.28069123 0.80811015 0.67448671]\n",
      " [1.4129747  1.27405327 0.42100785 0.82428539 0.77541586]\n",
      " [1.5138977  1.58186086 0.57174475 1.05331082 0.97810838]\n",
      " [1.08598248 1.34031071 0.63620106 0.81025977 0.81093006]\n",
      " [1.21828095 1.30183175 0.63003594 0.72328401 0.76484676]]\n"
     ]
    }
   ],
   "source": [
    "# ==> Evaluate above contractions w/ np.dot() <==\n",
    "# Define random matrices\n",
    "A = np.random.random((3, 5))\n",
    "B = np.random.random((3, 5))\n",
    "\n",
    "# Inner product\n",
    "M = A.dot(B.T)\n",
    "print(f\"The shape of the inner product is {M.shape}\")\n",
    "print(M)\n",
    "\n",
    "# Outer product\n",
    "#N = outer_product(A,B.T)\n",
    "N = A.T.dot(B)\n",
    "print(f\"The shape of the outer product is {N.shape}\")\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these two products, the dimensions of our two arrays are the same, even though they're rectangular.  What\n",
    "if only one dimension is shared, however?  Take for example a (4, 2) array $C$ and a (4, 5) array $D$.  Now, only\n",
    "an \"inner\" product between $C$ and $D$ makes sense, resulting in a (2, 5) array $R$:\n",
    "\n",
    "$${\\bf R}_{2\\times 5} = {\\bf C}^{T}\\times {\\bf D}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.45710931 2.44675519 1.96380962 1.38912083 1.59138581]\n",
      " [1.49395369 2.57284262 1.95392226 1.3892631  1.67327372]]\n"
     ]
    }
   ],
   "source": [
    "C = np.random.random((4, 2))\n",
    "D = np.random.random((4, 5))\n",
    "\n",
    "# Evaluate inner product\n",
    "R = C.T.dot(D)\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstein Summation Convention\n",
    "\n",
    "Just like the matrix multiplication, we may write these tensor contractions as summations.  To avoid writing out\n",
    "the sums, however (because we're lazy), we will introduce the _Einstein summation convention_:\n",
    ">In a tensor expression, repeated indices are contracted over.\n",
    "\n",
    "Therefore, we can rewrite each of the above tensor contractions more compactly as:\n",
    "1. Inner product:\n",
    "$$C_{ij} = \\sum_{i=1}^{M}\\sum_{k=1}^{N}\\sum_{j=1}^{P}A_{ik}B_{kj} = A_{ik}B_{kj}$$\n",
    "\n",
    "2. Outer product:\n",
    "$$C_{kk} = \\sum_{i=1}^{M}\\sum_{k=1}^{N}\\sum_{j=1}^{P}A_{ki}B_{jk} = A_{ki}B_{jk}$$\n",
    "\n",
    "Other than shortening the amount being written in each of these expressions, the Einstein summation convention\n",
    "also provides information directly about the shapes of the resulting array. To illustrate this, consider the\n",
    "following products, with example array shapes:\n",
    "\n",
    "| Einstein Summation | Example Shape |\n",
    "|--------------------|---------------|\n",
    "| $A_{ik}B_{kj}\\rightarrow C_{ij}$ | (2, 3) x (3, 4) $\\rightarrow$ (2, 4) |\n",
    "| $A_{ij}B_{ik}\\rightarrow C_{jk}$ | (2, 8) x (2, 5) $\\rightarrow$ (8, 5) |\n",
    "\n",
    "We've seen that we can use `np.dot()` to evaluate each of these contractions, however this approach is sometimes\n",
    "confusing, and doesn't seem to offer the same level of information as is provided in Einstein summation.  Plus,\n",
    "since many relevant equations are written down using the Einstein convention, wouldn't it be convenient if we\n",
    "could just use this convention directly when evaluating the contractions numerically?\n",
    "\n",
    "Well, we're in luck! NumPy offers a function specifically to do this, called `np.einsum()`, which takes as an\n",
    "argument the index \"map\" which defines the contraction, just like we've seen in the table above:\n",
    "\n",
    "| Einstein Summation | Example Shape | `np.einsum()` Call |\n",
    "|--------------------|---------------|--------------------|\n",
    "| $A_{ik}B_{kj}\\rightarrow C_{ij}$ | (2, 3) x (3, 4) $\\rightarrow$ (2, 4) | `np.einsum('ik,kj->ij', A, B)` |\n",
    "| $A_{ij}B_{ik}\\rightarrow C_{jk}$ | (5, 2) x (2, 5) $\\rightarrow$ (5, 8) | `np.einsum('ij,ik->jk', A, B)` |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5) (3, 5) (4, 2) (4, 5)\n",
      "[[0.87283543 1.0290475  0.28069123 0.80811015 0.67448671]\n",
      " [1.4129747  1.27405327 0.42100785 0.82428539 0.77541586]\n",
      " [1.5138977  1.58186086 0.57174475 1.05331082 0.97810838]\n",
      " [1.08598248 1.34031071 0.63620106 0.81025977 0.81093006]\n",
      " [1.21828095 1.30183175 0.63003594 0.72328401 0.76484676]]\n",
      "[[0.75451605 0.95647948 1.59433061 1.12403862]\n",
      " [2.20556582 2.1955936  2.65288728 1.45724928]\n",
      " [1.72562669 1.67415621 2.77309128 1.84641186]]\n",
      "4.29373998089209\n"
     ]
    }
   ],
   "source": [
    "print(A.shape, B.shape, C.shape, D.shape)\n",
    "\n",
    "print(np.einsum('ij,ik->jk', A, B))\n",
    "print(np.einsum('ik,jk->ij', A, D))\n",
    "print(np.einsum('ij,ij->', A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single biggest benefit to `np.einsum` is how explicitly the contractions are represented.  As an example,\n",
    "consider the following contractions between a rank-4 tensor $I$ and a rank-2 tensor $D$:\n",
    "$$J_{pq} = I_{pqrs}D_{rs}$$\n",
    "$$K_{pq} = I_{prqs}D_{rs}$$\n",
    "\n",
    "While it is not obvious how to perform these contractions with `np.dot()`, these operations are simple to\n",
    "translate into calls to `np.einsum()`.  In the cell below, try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12) (12, 12)\n"
     ]
    }
   ],
   "source": [
    "I = np.random.random((12, 12, 12, 12))\n",
    "D = np.random.random((12,12))\n",
    "\n",
    "J = np.einsum('pqrs,rs->pq', I, D)\n",
    "K = np.einsum('prqs,rs->pq', I, D)\n",
    "print(J.shape, K.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing our matrix multiply:\n",
      "CPU times: user 1min 43s, sys: 310 ms, total: 1min 44s\n",
      "Wall time: 1min 44s\n",
      "Timing np.einsum:\n",
      "CPU times: user 43.3 ms, sys: 1.45 ms, total: 44.8 ms\n",
      "Wall time: 46.3 ms\n",
      "Timing np.dot:\n",
      "CPU times: user 13.7 ms, sys: 4.73 ms, total: 18.4 ms\n",
      "Wall time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "# ==> Declare large-ish matrices for timings <==\n",
    "\n",
    "A = np.random.random((500,500))\n",
    "B = np.random.random((500,500))\n",
    "\n",
    "# Our hand-written matrix multiply\n",
    "print('Timing our matrix multiply:')\n",
    "%time mm_C = matmul(A, B)\n",
    "\n",
    "# Einsum\n",
    "print('Timing np.einsum:')\n",
    "%time es_C = np.einsum('ik,kj->ij', A, B)\n",
    "\n",
    "# Dot product\n",
    "print('Timing np.dot:')\n",
    "%time dot_C = A.dot(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Contraction Engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Student Answer Box\n",
    "1. Based on the experiences and use cases above, order the three contraction engines based on the following\n",
    "factors from \"best\" to \"worst\".  Justify your orderings.\n",
    "    1. Computational efficiency (speed)\n",
    "        - `np.dot` >  `np.einsum` >>> manual Python loops\n",
    "        - The timings are pretty clear.\n",
    "    2. Code clarity & readability\n",
    "        - `np.einsum` > `np.dot` $\\sim$ manual Python loops\n",
    "    3. Engine flexibility\n",
    "        - `np.einsum` > `np.dot` >>> manual Python loops\n",
    "    \n",
    "2. Based on your orderings, recommend a use case for each contraction engine.  Justify your recommendation.\n",
    "    1. Manual Python loops\n",
    "        - Either don't use or only use to teach the matrix multiplication formula.\n",
    "    2. NumPy Einsum\n",
    "        - Complicated contraction, etc. and want to be explicit while maintaining decent efficiency\n",
    "    3. NumPy Dot\n",
    "        - Any time that readability is not as important as speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(2 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
